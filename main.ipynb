{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eficientnet -> transformers -> camadas -> fine tuning -> svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('archive/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df_train.groupby('label', group_keys=False).apply(lambda x: x.sample(min(len(x), 1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sampled_df['file_name']\n",
    "Y = sampled_df['label']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_pasta_nova_ia = 'images/IA/'\n",
    "caminho_pasta_nova_human = 'images/HUMAN/'\n",
    "caminho_pasta_imagens= 'archive/train_data/'\n",
    "nome_imagens_df = X_train.values\n",
    "caminhodo = '/home/leonardo/Downloads/testando_cv/'\n",
    "caminho_teste_ia = 'validation/IA/'\n",
    "caminho_teste_human = 'validation/HUMAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in os.listdir(caminho_pasta_imagens):\n",
    "    if ';' in arquivo:  # Confere se o arquivo tem o padrão ;1 ou ;0\n",
    "        nome_imagem = arquivo.split(';')[0]  # Extrai o nome da imagem sem o ;1 ou ;0\n",
    "        \n",
    "        caminho_antigo = os.path.join(caminho_pasta_imagens, arquivo)\n",
    "        caminho_novo = os.path.join(caminho_pasta_imagens, nome_imagem)\n",
    "        \n",
    "        # Renomeia o arquivo\n",
    "        os.rename(caminho_antigo, caminho_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop sobre cada nome de imagem no DataFrame\n",
    "for nome_imagem, label in zip(X_train.values, Y_train. values):  # Supondo que a primeira coluna seja o nome das imagens\n",
    "    nome_imagem = nome_imagem[11:]\n",
    "    caminho_imagem_origem = os.path.join(caminho_pasta_imagens, nome_imagem)\n",
    "    caminho_imagem_origem = os.path.join(caminhodo, caminho_imagem_origem)\n",
    "    print(caminho_imagem_origem)\n",
    "    if label == 1:\n",
    "        caminho_imagem_destino = os.path.join(caminho_pasta_nova_ia, nome_imagem)\n",
    "    if label == 0:\n",
    "        caminho_imagem_destino = os.path.join(caminho_pasta_nova_human, nome_imagem)\n",
    "\n",
    "    \n",
    "    # Mover a imagem se existir\n",
    "    if os.path.exists(caminho_imagem_origem):\n",
    "        shutil.move(caminho_imagem_origem, caminho_imagem_destino)\n",
    "    else:\n",
    "        print('nao achei')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def contar_arquivos(diretorio):\n",
    "    return len([arquivo for arquivo in os.listdir(diretorio) if os.path.isfile(os.path.join(diretorio, arquivo))])\n",
    "\n",
    "# Caminho do diretório que você quer contar os arquivos\n",
    "caminho_diretorio = 'images/IA/'\n",
    "\n",
    "total_arquivos = contar_arquivos(caminho_diretorio)\n",
    "print(f\"Total de arquivos no diretório: {total_arquivos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calcular_hash(arquivo, buffer_size=65536):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(arquivo, 'rb') as f:\n",
    "        while chunk := f.read(buffer_size):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "def encontrar_arquivos_iguais(diretorio):\n",
    "    hashes = defaultdict(list)\n",
    "\n",
    "    for raiz, _, arquivos in os.walk(diretorio):\n",
    "        for arquivo in arquivos:\n",
    "            caminho_arquivo = os.path.join(raiz, arquivo)\n",
    "            hash_arquivo = calcular_hash(caminho_arquivo)\n",
    "            hashes[hash_arquivo].append(caminho_arquivo)\n",
    "    \n",
    "    # Retornar apenas os arquivos que possuem cópias\n",
    "    arquivos_duplicados = {hash_: caminhos for hash_, caminhos in hashes.items() if len(caminhos) > 1}\n",
    "    \n",
    "    return arquivos_duplicados\n",
    "\n",
    "# Caminho do diretório que você quer analisar\n",
    "caminho_diretorio = 'images/IA/'\n",
    "\n",
    "duplicados = encontrar_arquivos_iguais(caminho_diretorio)\n",
    "\n",
    "if duplicados:\n",
    "    print(\"Arquivos duplicados encontrados:\")\n",
    "    for hash_, arquivos in duplicados.items():\n",
    "        print(f\"\\nHash: {hash_}\")\n",
    "        for arquivo in arquivos:\n",
    "            print(f\" - {arquivo}\")\n",
    "else:\n",
    "    print(\"Nenhum arquivo duplicado encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_pasta_nova_ia = 'images/IA/'\n",
    "caminho_pasta_nova_human = 'images/HUMAN/'\n",
    "caminho_pasta_imagens= 'archive/train_data/'\n",
    "nome_imagens_df = X_train.values\n",
    "caminhodo = '/home/leonardo/Downloads/testando_cv/'\n",
    "caminho_teste_ia = 'validation/IA/'\n",
    "caminho_teste_human = 'validation/HUMAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop sobre cada nome de imagem no DataFrame\n",
    "for nome_imagem, label in zip(X_test.values, Y_test.values):  # Supondo que a primeira coluna seja o nome das imagens\n",
    "    nome_imagem = nome_imagem[11:]\n",
    "    caminho_imagem_origem = os.path.join(caminho_pasta_imagens, nome_imagem)\n",
    "    caminho_imagem_origem = os.path.join(caminhodo, caminho_imagem_origem)\n",
    "    print(caminho_imagem_origem)\n",
    "    if label == 1:\n",
    "        caminho_imagem_destino = os.path.join(caminho_teste_ia, nome_imagem)\n",
    "    if label == 0:\n",
    "        caminho_imagem_destino = os.path.join(caminho_teste_human, nome_imagem)\n",
    "\n",
    "    \n",
    "    # Mover a imagem se existir\n",
    "    if os.path.exists(caminho_imagem_origem):\n",
    "        shutil.move(caminho_imagem_origem, caminho_imagem_destino)\n",
    "    else:\n",
    "        print('nao achei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1624 images belonging to 2 classes.\n",
      "Found 390 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "treino_gen = datagen.flow_from_directory(\n",
    "    'images/',  # Caminho para o diretório de treino\n",
    "    target_size=(224, 224),  # Redimensiona todas as imagens para 224x224\n",
    "    batch_size=32,           # Número de imagens carregadas por vez\n",
    "    class_mode='binary'  # Tipo de classificação (categorical para múltiplas classes)\n",
    ")\n",
    "\n",
    "# Carregar imagens de teste\n",
    "teste_gen = datagen.flow_from_directory(\n",
    "    'validation/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HUMAN': 0, 'IA': 1}\n"
     ]
    }
   ],
   "source": [
    "print(treino_gen.class_indices)  # {'classe1': 0, 'classe2': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.legacy.preprocessing.image.DirectoryIterator at 0x7ffb5061bc10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m model_cnn_basic_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m                            kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     14\u001b[0m model_cnn_basic_1\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel_cnn_basic_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreino_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtreino_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/testando_cv/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Downloads/testando_cv/venv/lib/python3.10/site-packages/keras/src/utils/image_utils.py:227\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    A PIL Image instance.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[1;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "model_cnn_basic_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size = 3,\n",
    "                           activation=\"relu\",\n",
    "                           input_shape=(224,224,3)),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_cnn_basic_1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_cnn_basic_1.fit(treino_gen, epochs=5, validation_data=teste_gen, steps_per_epoch=len(treino_gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow está funcionando corretamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/leonardo/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "eog: symbol lookup error: /snap/core20/current/lib/x86_64-linux-gnu/libpthread.so.0: undefined symbol: __libc_pthread_init, version GLIBC_PRIVATE\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    img = Image.open(\"images/HUMAN/0a9fa1ee019a4781aa66049b7ed5475d.jpg\")\n",
    "    img.show()\n",
    "    print(\"Pillow está funcionando corretamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao abrir a imagem: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)  # Deve retornar '11.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1624\n"
     ]
    }
   ],
   "source": [
    "print(treino_gen.samples)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
